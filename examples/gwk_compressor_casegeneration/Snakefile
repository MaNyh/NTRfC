from snakemake.utils import validate
from snakemake.utils import Paramspace
import pandas as pd

from database.case_templates.templates import create_filelist_from_template
from database.case_templates.templates import case_templates

configfile : "casesettings.yaml"
validate(config,"config.schema.yaml")
TEMPLATENAME = config["case_params"]["case_type"]
TEMPLATE = case_templates[TEMPLATENAME]
TEMPLATE_PATH = TEMPLATE.path
TEMPLATE_SCHEMA = TEMPLATE.schema
DATASETS = create_filelist_from_template(TEMPLATENAME)
PARAMS=pd.read_csv("caseparams.tsv", sep="\t")
validate(PARAMS, TEMPLATE_SCHEMA)
paramspace = Paramspace(PARAMS)


rule all:
    input:
        # Aggregate over entire parameter space (or a subset thereof if needed)
        # of course, something like this can happen anywhere in the workflow (not
        # only at the end).
        *[f"01_Simulations/{instance_pattern}/{file}" for instance_pattern in paramspace.instance_patterns for file in DATASETS]

rule create_case:
    input:
        [f"{templatepath}/{file}" for templatepath in [TEMPLATE_PATH] for file in DATASETS ]
    output:
        # format a wildcard pattern like "alpha~{alpha}/beta~{beta}/gamma~{gamma}"
        # into a file path, with alpha, beta, gamma being the columns of the data frame
        *[f"01_Simulations/{paramspace.wildcard_pattern}/{file}" for file in DATASETS]
    params:
        case_type = config["case_params"]["case_type"],
        # automatically translate the wildcard values into an instance of the param space
        # in the form of a dict (here: {"alpha": ..., "beta": ..., "gamma": ...})
        simulation=paramspace.instance
    run:
        from ntrfc.preprocessing.case_creation.create_case import create_case
        create_case(input, output,params["case_type"],params["simulation"])
